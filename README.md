<p align="center">
  <img src="VowriteApp/Resources/AppIcon-source.png" alt="Vowrite" width="128">
</p>

# Vowrite ğŸ™ï¸

> **AI Voice Keyboard for macOS** â€” Speak naturally, get polished text inserted at your cursor.

[ğŸ‡¨ğŸ‡³ ä¸­æ–‡æ–‡æ¡£](README_CN.md)

Vowrite is a lightweight macOS menu bar app that turns your voice into clean, polished text â€” inserted right where your cursor is. Powered by OpenAI Whisper for transcription and GPT for text polishing.

No more typing. Just speak.

---

## âœ¨ Features

- ğŸ¤ **Voice-to-Text** â€” Press a hotkey, speak, get text
- âœ¨ **AI Polish** â€” Automatically removes filler words, fixes grammar, adds punctuation
- ğŸŒ **Multilingual** â€” Chinese, English, and mixed-language support
- ğŸ“‹ **Smart Injection** â€” Text appears directly at your cursor position
- ğŸ¯ **Works Everywhere** â€” Tested in native apps, browsers, Discord, VS Code, and more
- ğŸ¨ **Floating Overlay** â€” Compact recording bar with smooth waveform animation
- âŒ¨ï¸ **Customizable Hotkey** â€” Default: `âŒ¥ Space` (Option + Space)
- â‹ **ESC to Cancel** â€” Press Escape to instantly cancel recording
- ğŸ“Š **History** â€” Browse and search past dictations
- ğŸ”Œ **Multi-Provider** â€” OpenAI, OpenRouter, Groq, Together AI, DeepSeek, or bring your own

## ğŸš€ Quick Start

### Download

Download the latest release from [GitHub Releases](https://github.com/Joevonlong/Vowrite/releases).

### Build from Source

```bash
cd VowriteApp
./build.sh
```

Or manually:

```bash
cd VowriteApp
swift build -c release
cp .build/arm64-apple-macosx/release/Vowrite Vowrite.app/Contents/MacOS/Vowrite
codesign -fs - --deep --entitlements Resources/Vowrite.entitlements Vowrite.app
open Vowrite.app
```

### Setup

1. Launch Vowrite â€” it appears in the menu bar as a ğŸ¤ icon
2. Open **Settings** â†’ enter your API key ([Get one from OpenAI](https://platform.openai.com/api-keys))
3. Grant **Microphone** and **Accessibility** permissions when prompted
4. Press `âŒ¥ Space` to start recording, press again to stop
5. Text is automatically inserted at your cursor âœ¨

## ğŸ”§ How It Works

```
ğŸ¤ Record â†’ ğŸ“ Transcribe â†’ âœ¨ Polish â†’ ğŸ“‹ Insert
```

1. **Record** â€” Audio captured as AAC via AVAudioEngine
2. **Transcribe** â€” Sent to Whisper API for speech-to-text
3. **Polish** â€” GPT cleans up filler words, grammar, and punctuation
4. **Insert** â€” Text injected at your cursor via clipboard paste or Unicode typing

### Text Injection Methods

| Method | Speed | Requires |
|--------|-------|----------|
| **Clipboard Paste** (default) | âš¡ Instant | Accessibility permission |
| **Unicode Typing** (fallback) | Fast | Nothing â€” works everywhere |

Vowrite automatically detects permissions and picks the best method.

## ğŸ”Œ Supported Providers

| Provider | STT Model | Polish Model |
|----------|-----------|-------------|
| **OpenAI** | whisper-1 | gpt-4o-mini |
| OpenRouter | whisper-large-v3 | gpt-4o-mini |
| Groq | whisper-large-v3-turbo | llama-3.1-8b-instant |
| Together AI | whisper-large-v3 | Llama-3.1-8B-Instruct-Turbo |
| DeepSeek | whisper-1 | deepseek-chat |
| Custom | configurable | configurable |

## ğŸ“ Project Structure

```
VowriteApp/
â”œâ”€â”€ App/                        # App lifecycle & state
â”œâ”€â”€ Core/
â”‚   â”œâ”€â”€ Audio/                  # Microphone recording
â”‚   â”œâ”€â”€ STT/                    # Speech-to-text (Whisper)
â”‚   â”œâ”€â”€ AI/                     # Text polishing (GPT)
â”‚   â”œâ”€â”€ TextInjection/          # Cursor text injection
â”‚   â”œâ”€â”€ Hotkey/                 # Global hotkey management
â”‚   â””â”€â”€ Keychain/               # Secure API key storage
â”œâ”€â”€ Views/                      # SwiftUI views
â”œâ”€â”€ Models/                     # SwiftData models
â”œâ”€â”€ Resources/                  # Info.plist, entitlements
â””â”€â”€ build.sh                    # Build script
```

## ğŸ“‹ Requirements

- macOS 14.0 (Sonoma) or later
- API key from a supported provider (OpenAI recommended)
- Microphone permission
- Accessibility permission (recommended, not required)

## ğŸ—ºï¸ Roadmap

- [x] **v0.1** â€” Core voice dictation
- [x] **v0.2** â€” Release packaging & error handling
- [x] **v0.3** â€” App icon & branding
- [ ] **v0.4** â€” Custom prompts, multiple output modes
- [ ] **v0.4** â€” Real-time streaming, local Whisper
- [ ] **v1.0** â€” Code signing, notarization, auto-update

See [full roadmap](ops/ROADMAP.md) for details.

## ğŸ“„ License

MIT License â€” see [LICENSE](LICENSE) for details.

## ğŸ¤ Contributing

Contributions welcome! Please open an issue first to discuss what you'd like to change.

## ğŸ“ Changelog

### v0.3 â€” App Icon
- Official app icon (waveform ring + text cursor design)
- Icon generation automation script
- Build pipeline integration

### v0.2 â€” Release Ready
- Release build optimization (debug logs disabled in production)
- User-friendly error messages
- Automated DMG packaging

### v0.1 â€” Initial Release
- Voice dictation with Whisper STT + GPT polish
- Menu bar app with floating recording overlay
- Customizable hotkey (default âŒ¥Space)
- Multi-provider support
- Dual text injection (clipboard paste + Unicode typing fallback)
- Dictation history with SwiftData
- Microphone selection & launch at login
